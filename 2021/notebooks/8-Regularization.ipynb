{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression: Regularization\n",
    "\n",
    "The data below comes from a study by Stamey et al. (1989), which examines the correlation between the level of prostate-specific antigen (PSA). The example is covered in Section 3.2.1 if Hastie et al. *Elements of Statistical Learning*.\n",
    "\n",
    "* [Step 1: Loading the Dataset](#step1)\n",
    "* [Step 2: Training and Testing the Basic Model](#step2)\n",
    "* [Step 3: Regularization](#step3)\n",
    "\n",
    "The first two parts of this lab are a review from previous labs, so you can skip ahead to Step 3 and run all of the cells above.\n",
    "\n",
    "\n",
    "## Step 1: Loading the Normalized Prostate Cancer Dataset\n",
    "<a id='step1'></a>\n",
    "\n",
    "To explore regularization, we will load the prostate cancer dataset that we used in a previous notebook, normalizing and preparing the features as before.\n",
    "\n",
    "We'll perform all of these steps at once in this lab. Refer to the previous notebook for detailed explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lcavol</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300232</td>\n",
       "      <td>0.286324</td>\n",
       "      <td>0.063168</td>\n",
       "      <td>0.592949</td>\n",
       "      <td>0.692043</td>\n",
       "      <td>0.426414</td>\n",
       "      <td>0.483161</td>\n",
       "      <td>0.733155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lweight</th>\n",
       "      <td>0.300232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.316723</td>\n",
       "      <td>0.437042</td>\n",
       "      <td>0.181054</td>\n",
       "      <td>0.156829</td>\n",
       "      <td>0.023558</td>\n",
       "      <td>0.074166</td>\n",
       "      <td>0.485215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.286324</td>\n",
       "      <td>0.316723</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.287346</td>\n",
       "      <td>0.128902</td>\n",
       "      <td>0.172951</td>\n",
       "      <td>0.365915</td>\n",
       "      <td>0.275806</td>\n",
       "      <td>0.227642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lbph</th>\n",
       "      <td>0.063168</td>\n",
       "      <td>0.437042</td>\n",
       "      <td>0.287346</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.139147</td>\n",
       "      <td>-0.088535</td>\n",
       "      <td>0.032992</td>\n",
       "      <td>-0.030404</td>\n",
       "      <td>0.262938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svi</th>\n",
       "      <td>0.592949</td>\n",
       "      <td>0.181054</td>\n",
       "      <td>0.128902</td>\n",
       "      <td>-0.139147</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.671240</td>\n",
       "      <td>0.306875</td>\n",
       "      <td>0.481358</td>\n",
       "      <td>0.556886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcp</th>\n",
       "      <td>0.692043</td>\n",
       "      <td>0.156829</td>\n",
       "      <td>0.172951</td>\n",
       "      <td>-0.088535</td>\n",
       "      <td>0.671240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.476437</td>\n",
       "      <td>0.662533</td>\n",
       "      <td>0.489203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gleason</th>\n",
       "      <td>0.426414</td>\n",
       "      <td>0.023558</td>\n",
       "      <td>0.365915</td>\n",
       "      <td>0.032992</td>\n",
       "      <td>0.306875</td>\n",
       "      <td>0.476437</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.757056</td>\n",
       "      <td>0.342428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgg45</th>\n",
       "      <td>0.483161</td>\n",
       "      <td>0.074166</td>\n",
       "      <td>0.275806</td>\n",
       "      <td>-0.030404</td>\n",
       "      <td>0.481358</td>\n",
       "      <td>0.662533</td>\n",
       "      <td>0.757056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.448048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lpsa</th>\n",
       "      <td>0.733155</td>\n",
       "      <td>0.485215</td>\n",
       "      <td>0.227642</td>\n",
       "      <td>0.262938</td>\n",
       "      <td>0.556886</td>\n",
       "      <td>0.489203</td>\n",
       "      <td>0.342428</td>\n",
       "      <td>0.448048</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           lcavol   lweight       age      lbph       svi       lcp   gleason  \\\n",
       "lcavol   1.000000  0.300232  0.286324  0.063168  0.592949  0.692043  0.426414   \n",
       "lweight  0.300232  1.000000  0.316723  0.437042  0.181054  0.156829  0.023558   \n",
       "age      0.286324  0.316723  1.000000  0.287346  0.128902  0.172951  0.365915   \n",
       "lbph     0.063168  0.437042  0.287346  1.000000 -0.139147 -0.088535  0.032992   \n",
       "svi      0.592949  0.181054  0.128902 -0.139147  1.000000  0.671240  0.306875   \n",
       "lcp      0.692043  0.156829  0.172951 -0.088535  0.671240  1.000000  0.476437   \n",
       "gleason  0.426414  0.023558  0.365915  0.032992  0.306875  0.476437  1.000000   \n",
       "pgg45    0.483161  0.074166  0.275806 -0.030404  0.481358  0.662533  0.757056   \n",
       "lpsa     0.733155  0.485215  0.227642  0.262938  0.556886  0.489203  0.342428   \n",
       "\n",
       "            pgg45      lpsa  \n",
       "lcavol   0.483161  0.733155  \n",
       "lweight  0.074166  0.485215  \n",
       "age      0.275806  0.227642  \n",
       "lbph    -0.030404  0.262938  \n",
       "svi      0.481358  0.556886  \n",
       "lcp      0.662533  0.489203  \n",
       "gleason  0.757056  0.342428  \n",
       "pgg45    1.000000  0.448048  \n",
       "lpsa     0.448048  1.000000  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv(\"../../data/prostate.data\", sep='\\t')\n",
    "\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "df.head(5)\n",
    "\n",
    "df_train = df[df['train']=='T']\n",
    "df_test = df[df['train']=='F']\n",
    "\n",
    "df_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.350010</td>\n",
       "      <td>3.628943</td>\n",
       "      <td>63.865979</td>\n",
       "      <td>0.100356</td>\n",
       "      <td>0.216495</td>\n",
       "      <td>-0.179366</td>\n",
       "      <td>6.752577</td>\n",
       "      <td>24.381443</td>\n",
       "      <td>2.478387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.178625</td>\n",
       "      <td>0.428411</td>\n",
       "      <td>7.445117</td>\n",
       "      <td>1.450807</td>\n",
       "      <td>0.413995</td>\n",
       "      <td>1.398250</td>\n",
       "      <td>0.722134</td>\n",
       "      <td>28.204035</td>\n",
       "      <td>1.154329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lcavol   lweight        age      lbph       svi       lcp   gleason  \\\n",
       "mean  1.350010  3.628943  63.865979  0.100356  0.216495 -0.179366  6.752577   \n",
       "std   1.178625  0.428411   7.445117  1.450807  0.413995  1.398250  0.722134   \n",
       "\n",
       "          pgg45      lpsa  \n",
       "mean  24.381443  2.478387  \n",
       "std   28.204035  1.154329  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().loc[['mean', 'std']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the Features\n",
    "\n",
    "We must normalize our features to have mean 0 and standard deviation of 1, up to computational errors.\n",
    "Importantly, we need to normalize train and test sets separately, using means and sds of train set's columns for normalizing test set. For an explanation on why: https://sebastianraschka.com/faq/docs/scale-training-test.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.308328e-17</td>\n",
       "      <td>-4.971148e-18</td>\n",
       "      <td>-8.343243e-16</td>\n",
       "      <td>6.628197e-18</td>\n",
       "      <td>3.976918e-17</td>\n",
       "      <td>-4.308328e-17</td>\n",
       "      <td>4.921436e-16</td>\n",
       "      <td>-3.314099e-17</td>\n",
       "      <td>2.452345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.007547e+00</td>\n",
       "      <td>1.007547e+00</td>\n",
       "      <td>1.007547e+00</td>\n",
       "      <td>1.007547e+00</td>\n",
       "      <td>1.007547e+00</td>\n",
       "      <td>1.007547e+00</td>\n",
       "      <td>1.007547e+00</td>\n",
       "      <td>1.007547e+00</td>\n",
       "      <td>1.207812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            lcavol       lweight           age          lbph           svi  \\\n",
       "mean  4.308328e-17 -4.971148e-18 -8.343243e-16  6.628197e-18  3.976918e-17   \n",
       "std   1.007547e+00  1.007547e+00  1.007547e+00  1.007547e+00  1.007547e+00   \n",
       "\n",
       "               lcp       gleason         pgg45      lpsa  \n",
       "mean -4.308328e-17  4.921436e-16 -3.314099e-17  2.452345  \n",
       "std   1.007547e+00  1.007547e+00  1.007547e+00  1.207812  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize(df, scaler=None):\n",
    "    '''\n",
    "    If scaler is not none, use given scaler's means and sds to normalize (used for test set case)\n",
    "    '''\n",
    "    # Will not normalize the response (or outcomes), only the predictors (features)\n",
    "\n",
    "    # Normalizing train set\n",
    "    if(scaler is None):\n",
    "      scaler = StandardScaler()\n",
    "      normalized_features = scaler.fit_transform(pd.DataFrame(df.iloc[:,:-1])) \n",
    "\n",
    "    # Normalizing test set (with the values based on the training set)\n",
    "    else:\n",
    "      normalized_features = scaler.transform(pd.DataFrame(df.iloc[:,:-1]))\n",
    "        \n",
    "    outcomes = df.iloc[:,-1]\n",
    "    normalized_df = pd.DataFrame(normalized_features)\n",
    "      \n",
    "    # Recover the outcomes column\n",
    "    normalized_df['outcome'] = outcomes.tolist() #We use .tolist() to avoid conflict given different index between normalized_df and outcomes\n",
    "    \n",
    "    # Recover the original indices and column names                                          \n",
    "    normalized_df.index=df.index\n",
    "    normalized_df.columns=df.columns\n",
    "\n",
    "    return normalized_df, scaler\n",
    "  \n",
    "# Normalize training\n",
    "df_train_train_column = df_train['train']\n",
    "df_train, scaler = normalize(df_train.drop(columns=['train']))\n",
    "df_train['train'] = df_train_train_column\n",
    "\n",
    "df_train.describe().loc[['mean', 'std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095740</td>\n",
       "      <td>0.019378</td>\n",
       "      <td>-0.382254</td>\n",
       "      <td>0.064359</td>\n",
       "      <td>-0.057289</td>\n",
       "      <td>0.081023</td>\n",
       "      <td>0.097586</td>\n",
       "      <td>-0.209818</td>\n",
       "      <td>2.536547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.840554</td>\n",
       "      <td>0.636143</td>\n",
       "      <td>0.945937</td>\n",
       "      <td>0.994212</td>\n",
       "      <td>0.975998</td>\n",
       "      <td>1.016637</td>\n",
       "      <td>1.081828</td>\n",
       "      <td>0.878424</td>\n",
       "      <td>1.042035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lcavol   lweight       age      lbph       svi       lcp   gleason  \\\n",
       "mean  0.095740  0.019378 -0.382254  0.064359 -0.057289  0.081023  0.097586   \n",
       "std   0.840554  0.636143  0.945937  0.994212  0.975998  1.016637  1.081828   \n",
       "\n",
       "         pgg45      lpsa  \n",
       "mean -0.209818  2.536547  \n",
       "std   0.878424  1.042035  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize test, using scaler from train set normalization\n",
    "df_test_train_column = df_test['train']\n",
    "df_test, _ = normalize(df_test.drop(columns=['train']), scaler)\n",
    "df_test['train'] = df_test_train_column\n",
    "\n",
    "df_test.describe().loc[['mean', 'std']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "## Step 2: Training and Testing the Basic Model (Review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we separate the data into the features that we are use for inputs and the target variable that we are trying to predict (lpsa).\n",
    "\n",
    "This step performs a standard linear regression on the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias: 0.44\n",
      "Mean squared error: 0.52\n",
      "RSS: 15.64\n",
      "Variance score: 0.69\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_features = df_train.loc[:,'lcavol':'pgg45']\n",
    "train_targets = df_train.loc[:,'lpsa']\n",
    "\n",
    "test_features = df_test.loc[:,'lcavol':'pgg45']\n",
    "test_targets = df_test.loc[:,'lpsa']\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(train_features,train_targets)\n",
    "\n",
    "target_predict = regr.predict(test_features)\n",
    "\n",
    "\n",
    "def metrics(target_predict,test_targets,train_features,train_targets,regr,output=True):\n",
    "    \n",
    "    bias = mean_squared_error(regr.predict(train_features),train_targets)\n",
    "    mse = mean_squared_error(target_predict,test_targets)\n",
    "    rss = np.sum((target_predict - test_targets) ** 2)\n",
    "    variance = regr.score(train_features, train_targets)\n",
    "    \n",
    "    if output:\n",
    "        print(\"Bias: %.2f\" % bias)   \n",
    "        print(\"Mean squared error: %.2f\" % mse)\n",
    "        print(\"RSS: %.2f\" % rss)\n",
    "        print('Variance score: %.2f\\n' % variance)\n",
    "    \n",
    "    return(bias,mse,rss,variance)\n",
    "\n",
    "ev = {}\n",
    "ev['Linear Regression'] = metrics(target_predict,test_targets,train_features,train_targets,regr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "## Step 3: Basis Expansion, Regularization\n",
    "\n",
    "We'll perform a polynomial basis expansion (degree 2) on the dataset we've used before as a basis for comparison.\n",
    "\n",
    "\n",
    "### Polynomial Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias: 0.17\n",
      "Mean squared error: 1.08\n",
      "RSS: 32.35\n",
      "Variance score: 0.88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "pf = PolynomialFeatures(degree=2, include_bias=False)\n",
    "p_train_features = pf.fit_transform(train_features)\n",
    "p_test_features = pf.fit_transform(test_features)\n",
    "\n",
    "pregr = linear_model.LinearRegression()\n",
    "pregr.fit(p_train_features,train_targets)\n",
    "\n",
    "p_target_predict = pregr.predict(p_test_features)\n",
    "\n",
    "\n",
    "ev['Linear Polynomial'] = metrics(p_target_predict,test_targets,p_train_features,train_targets,pregr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "\n",
    "Now we'll explore three different types of regularization:\n",
    "\n",
    "* Lasso: Penalizes the sum of absolute values of all parameter coefficients.\n",
    "* Ridge: Penalizes the sum of squares of all parameter coefficients.\n",
    "* Elastic Network: Combines Lasso and Ridge Regression\n",
    "\n",
    "The $\\alpha$ is tunable between 0 and 1. Higher values of $\\alpha$ reflect a higher penalty for more complex models and thus result in more coefficients being removed/set to zero. You can play with the alpha parameters below to explore these effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lcavol', 'lweight', 'age', 'lbph', 'svi', 'lcp', 'gleason', 'pgg45', 'lpsa', 'train'] \n",
      "\n",
      "\n",
      "Lasso\n",
      "[0.37888041 0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "\n",
      "Bias: 0.91\n",
      "Mean squared error: 0.68\n",
      "RSS: 20.31\n",
      "Variance score: 0.36\n",
      "\n",
      "Ridge\n",
      "[ 0.69784742  0.2900597  -0.13783385  0.20941857  0.30440194 -0.27010395\n",
      " -0.01574426  0.26516801]\n",
      "\n",
      "Bias: 0.44\n",
      "Mean squared error: 0.52\n",
      "RSS: 15.50\n",
      "Variance score: 0.69\n",
      "\n",
      "Elastic Net\n",
      "[0.40593487 0.15041169 0.         0.         0.11168684 0.\n",
      " 0.         0.02084413]\n",
      "\n",
      "Bias: 0.68\n",
      "Mean squared error: 0.54\n",
      "RSS: 16.13\n",
      "Variance score: 0.52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(list(df_train), '\\n\\n')\n",
    "\n",
    "ls = linear_model.Lasso(alpha=0.5)\n",
    "rg = linear_model.Ridge(alpha=0.5)\n",
    "en = linear_model.ElasticNet(alpha=0.5)\n",
    "\n",
    "models = [(ls, 'Lasso'),\n",
    "           (rg, 'Ridge'),\n",
    "           (en, 'Elastic Net')]\n",
    "\n",
    "for m in models:\n",
    "    (model,name) = m\n",
    "    model.fit(train_features,train_targets)\n",
    "    target_predict = model.predict(test_features)\n",
    "    print('{}\\n{}\\n'.format(name,model.coef_))\n",
    "    ev[name] = metrics(target_predict,test_targets,train_features,train_targets,model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Shrinkage: Feature Subset (Review/Comparison)\n",
    "\n",
    "Recall from an earlier lab on MSE and feature importance that we used Z-scores to identify important parameters and trained the model on fewer number parameters. Here we manually create a linear regression model based on a partial subset of features, retaining only the features that are most important.\n",
    "\n",
    "We can compare the performance of this model, based on Z-Scores, to the other regularization methods above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset (Manual)\n",
      "[0.64128976 0.34852683 0.22422118]\n",
      "\n",
      "Bias: 0.52\n",
      "Mean squared error: 0.40\n",
      "RSS: 12.02\n",
      "Variance score: 0.64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "name = 'Subset (Manual)'\n",
    "sregr = linear_model.LinearRegression()\n",
    "\n",
    "# Train on fewer coefficients. \n",
    "train_features_small = df_train.loc[:,['lcavol','lweight','svi']]\n",
    "test_features_small = df_test.loc[:,['lcavol','lweight','svi']]\n",
    "sregr.fit(train_features_small,train_targets)\n",
    "target_predict_small = sregr.predict(test_features_small)\n",
    "\n",
    "print('{}\\n{}\\n'.format(name,sregr.coef_))\n",
    "\n",
    "ev['Subset (Manual)'] = metrics(target_predict_small,test_targets,train_features_small,train_targets,sregr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Results\n",
    "\n",
    "Below, we compare the bias, variance, and MSE of the different models. We can see below that there is a clear (fundamental) tradeoff between bias and variance. Some of the models with high variance and high MSE (such as the degree 2 polynomial expansion) are clearly overfit\n",
    "\n",
    "Other models have balanced the tradeoff, and maintain a relatively low MSE on the test set as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "\n",
    "mdf = pd.DataFrame(\n",
    "    ev\n",
    ").transpose()\n",
    "\n",
    "mdf.index.name = 'Type'\n",
    "mdf.rename(columns={0:'Bias',1:'MSE',2:'RSS',3:'Variance'},inplace=True)\n",
    "mdf.sort_values(by=['Bias'],inplace=True)\n",
    "\n",
    "labels = mdf.index.values\n",
    "x = np.arange(len(labels))\n",
    "width = 0.35  \n",
    "\n",
    "fix, ax = plt.subplots()\n",
    "rects = ax.bar(x - width/3, mdf['Bias'], width/3, label='Bias')\n",
    "rects = ax.bar(x, mdf['Variance'], width/3, label='Variance')\n",
    "rects = ax.bar(x + width/3, mdf['MSE'], width/3, label='MSE')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, rotation=45)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
