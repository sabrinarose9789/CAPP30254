{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naïve Bayes Classification\n",
    "\n",
    "In this lab, we'll explore some of our familiar datasets in the context of the naïve Bayes classifier. The Naïve Bayes classifier is popular in machine learning due to its interpretability, as well as its good performance on relatively small datasets.\n",
    "\n",
    "Naïve Bayes maximizes the posterior probability of the target variable, $y$, being of a particular class $C$, given a set of observations, $X$.\n",
    "\n",
    "<p>\n",
    "<center>\n",
    "$\\hat{y} = \\mathrm{argmax}_y \\left(P(y=C | X = {x_1, x_2 \\ldots, x_n})\\right)$\n",
    "</center>\n",
    "</p>\n",
    "\n",
    "Applying Bayes' Rule, it is possible to show that maximizing this quantity is equivalent to:\n",
    "\n",
    "<p>\n",
    "<center>\n",
    "$\\hat{y} = \\mathrm{argmax}_y \\left(P(y=C) \\cdot \\Pi_{i=1}^n p(x_i|y))\\right)$\n",
    "</center>\n",
    "</p>\n",
    "\n",
    "Performing this computation requires assuming a particular probability distribution over the features.  Common assumptions about statistical distributions include:\n",
    "* **Gaussian (Normal) Distribution:** Appropriate for continuous valued features\n",
    "* **Bernoulli Distribution:** Appropriate for categorical features\n",
    "* **Multinomial Distribution:** Appropriate for counts or range features.\n",
    "\n",
    "\n",
    "In this lab, we will explore some basic probabilities using the Chicago Crime Dataset, implement a version of a Naïve Bayes classifier by hand, and then apply some of the libraries in `sklearn` to perform some more sophisticated classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Pandas and Numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import Plotting Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Chicago Crime Data\n",
    "\n",
    "Let's revisit the crime data that we've been exploring in some of our previous labs, and clean it up as before.\n",
    "\n",
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Block</th>\n",
       "      <th>IUCR</th>\n",
       "      <th>Primary Type</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location Description</th>\n",
       "      <th>Arrest</th>\n",
       "      <th>Domestic</th>\n",
       "      <th>...</th>\n",
       "      <th>Ward</th>\n",
       "      <th>Community Area</th>\n",
       "      <th>FBI Code</th>\n",
       "      <th>X Coordinate</th>\n",
       "      <th>Y Coordinate</th>\n",
       "      <th>Year</th>\n",
       "      <th>Updated On</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11922110</td>\n",
       "      <td>JC547456</td>\n",
       "      <td>12/15/2019 03:40:00 AM</td>\n",
       "      <td>039XX W NORTH AVE</td>\n",
       "      <td>1020</td>\n",
       "      <td>ARSON</td>\n",
       "      <td>BY FIRE</td>\n",
       "      <td>VEHICLE NON-COMMERCIAL</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>09</td>\n",
       "      <td>1149951.0</td>\n",
       "      <td>1910348.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>04/27/2020 03:48:23 PM</td>\n",
       "      <td>41.909907</td>\n",
       "      <td>-87.724578</td>\n",
       "      <td>(41.909907002, -87.724577987)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID Case Number                    Date              Block  IUCR  \\\n",
       "0  11922110    JC547456  12/15/2019 03:40:00 AM  039XX W NORTH AVE  1020   \n",
       "\n",
       "  Primary Type Description    Location Description  Arrest  Domestic  ...  \\\n",
       "0        ARSON     BY FIRE  VEHICLE NON-COMMERCIAL   False     False  ...   \n",
       "\n",
       "   Ward  Community Area  FBI Code  X Coordinate Y Coordinate  Year  \\\n",
       "0  26.0            23.0        09     1149951.0    1910348.0  2019   \n",
       "\n",
       "               Updated On   Latitude  Longitude                       Location  \n",
       "0  04/27/2020 03:48:23 PM  41.909907 -87.724578  (41.909907002, -87.724577987)  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../data/chicago-crimes-2019.csv.gz\", compression='gzip')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Features\n",
    "\n",
    "Let's drop the records that have NaN values, making sure there aren't too many of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 NaN community area records.\n"
     ]
    }
   ],
   "source": [
    "print(\"Found {} NaN community area records.\".format(df['Community Area'].isna().sum()))\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the Features\n",
    "\n",
    "Let's turn arest into a 0/1 binary variable\n",
    "\n",
    "Let's also re-create the hour of the day column, since that's a feature we like to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hour'] = pd.to_datetime(df['Date']).dt.hour\n",
    "df['Community Area'] = df['Community Area'].astype(int)\n",
    "df['Hour'] = df['Hour'].astype(int)\n",
    "df['Arrest'] = df['Arrest'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's suppose that, as in the Support Vector Machine lab, we want to build a binary classifier that predicts arrests based on hour of the day and community area.\n",
    "\n",
    "In this case, the target variable $y$ is the `Arrest` column, and our features are the `Community Area` and `Hour` Columns. Let's create a dataframe to work just with those columns within this section of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_backup = df.copy()\n",
    "df = df.loc[:,['Hour', 'Community Area', 'Arrest']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Classification by Hand\n",
    "\n",
    "To understand the intuition behind the Naïve Bayes Classifier, let's first compute all of our posterior probabilities by hand.\n",
    "\n",
    "### Prior Probabilities for Each Class\n",
    "\n",
    "We first need to compute our prior probabilities for the target variable `Arrest`. Below, we've computed the complement directly just as a sanity check on our data; we could have used $1-p$ for the complement, but this helps us see that everything is accounted for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(y=0) =     0.2139\n",
      "P(y=1) =     0.7861\n"
     ]
    }
   ],
   "source": [
    "arrests = df[df['Arrest']==1]['Arrest'].count()\n",
    "no_arrests = df[df['Arrest']==0]['Arrest'].count()\n",
    "total = df['Arrest'].count()\n",
    "\n",
    "# Probability of Arrest\n",
    "p_y = [arrests / total,\n",
    "        no_arrests / total]\n",
    "\n",
    "print(\"P(y=0) = {:10.4f}\\nP(y=1) = {:10.4f}\".format(p_y[0],p_y[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Likelihood for Each Class\n",
    "\n",
    "Now we compute the feature likelihood for each class. A typical way to do this is with parameter estimation, by assuming a distribution of the features (e.g., gaussian, multinomial). Here we'll start with something much simpler: We'll assume the likelihood $P(x1,x2|y)$ is simply the values in the dataset itself. \n",
    "\n",
    "In other words, we'll just say that the likelihood of the probability for a given community area and hour, given arrest or no arrest, is simply the number of observations of a (community area, hour) tuple in the event of arrest (or no arrest), divided by the total number of arrest (or no arrest) events.\n",
    "\n",
    "There are $24 \\times 77 \\times 2$ such values to compute: One for each neighborhood area (77) and hour of the day (24), for each class of outcomes (arrest, no arrest):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could have used ranges for these, but best to derive directly from the data and not make any assumptions.\n",
    "ca = np.sort(df['Community Area'].unique())\n",
    "hr = np.sort(df['Hour'].unique())\n",
    "\n",
    "arrest = [no_arrests,arrests]\n",
    "likelihood = [[ [0 for col in range(2)] for col in range(24)] for row in range(78)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`likelihood[c][h][a]` contains $P(\\mathrm{community\\; area, hour} | \\mathrm{arrest})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a subset of the dataframe for y=1 since we'll need this a lot\n",
    "for c in ca:\n",
    "    for h in hr:\n",
    "        for a in (0,1):\n",
    "            likelihood[c][h][a] = df[(df['Community Area']==c) & \\\n",
    "                                     (df['Hour']==h) & \\\n",
    "                                     (df['Arrest']==a)].count()[0] / arrest[a]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check that conditional probabilities sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999976"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 0\n",
    "for c in ca:\n",
    "    for h in hr:\n",
    "        s = s + likelihood[c][h][0]\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions\n",
    "\n",
    "Given an incident in a given community area and hour, can we predict whether an arrest was made? This is probably not a very good classifier, given the limited number of features we're using, but we'll demonstrate for the sake of example.\n",
    "\n",
    "Essentially, given a community area and hour, we need to find the value of $y$ (i.e., arrest) that is most likely, given the observed $X$ (hour, community area).\n",
    "\n",
    "This can be performed by picking the value of `likelihood[c][h][a]` $\\cdot$ `p_y[i]` (for i=0 or 1) (the prior probability of arrest).\n",
    "\n",
    "#### Hyde Park, 10 a.m.\n",
    "\n",
    "Hyde Park is area 41.  If the incident is at 1000h, will an arrest take place?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood[41][10][0] * p_y[0] < likelihood[41][10][1] * p_y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12880841153745723"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 0\n",
    "h = 10\n",
    "n = 41\n",
    "for a in (0,1):\n",
    "    s = s + likelihood[n][h][a]\n",
    "\n",
    "likelihood[n][h][1]/s * p_y[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Austin, 10 a.m.\n",
    "\n",
    "Austin is area 25. If the incident is at 1000h, will an arrest take place?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood[25][10][0] * p_y[0] < likelihood[25][10][1] * p_y[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naïve Bayes with Scikit-Learn\n",
    "\n",
    "Now we will perform the same computation with Python's `sklearn` library. We'll use the `ComplementNB` class, which is an adaptation of the multinomial Naïve Bayes classifier that deals better with imbalanced datasets. The technique is described in more detail in this [paper](https://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Naïve Bayes Classifiers. (We'll only use Multinomial for now.)\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "nb = ComplementNB() \n",
    "\n",
    "features = df.loc[:,['Community Area', 'Hour']].values\n",
    "target = df['Arrest'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyde Park, 10 a.m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(features,target)\n",
    "nb.predict([[41,10]])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Austin, 10 a.m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict([[25,10]])[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
